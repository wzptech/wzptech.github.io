

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Weizhi Peng</title>
  <subtitle>A minimal, responsive, and powerful Jekyll theme for presenting professional writing.</subtitle>
  <updated>2022-09-10T17:58:43+08:00</updated>
  <author>
    <name>Weizhi Peng</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator>
  <rights> Â© 2022 Weizhi Peng </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Clustering</title>
    <link href="http://localhost:4000/posts/Clustering/" rel="alternate" type="text/html" title="Clustering" />
    <published>2022-04-21T07:32:00+08:00</published>
  
    <updated>2022-04-21T07:32:00+08:00</updated>
  
    <id>http://localhost:4000/posts/Clustering/</id>
    <content src="http://localhost:4000/posts/Clustering/" />
    <author>
      <name>Weizhi Peng</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="Clustering" />
    
  

  
    <summary>
      





      Unsupervised Learning

Clustering





K-means









Kmeans python code

import numpy as np
m = [
    [2,2],
    [5,1]
]

X = [
    [3,4],
    [5,1],
    [3,7],
    [9,6],
    [2,2],
    [7,0]
]
result = []
while True:
    x_m = [(np.array(X) - np.array(center)) for center in m]
    distance = [np.sqrt(np.sum(np.power(item,2),axis=1)) for item in x_m]
    class_selection = np.argmax(np.trans...
    </summary>
  

  </entry>

  
  <entry>
    <title>Ensemble Methods</title>
    <link href="http://localhost:4000/posts/Ensemble-Methods/" rel="alternate" type="text/html" title="Ensemble Methods" />
    <published>2022-04-11T07:32:00+08:00</published>
  
    <updated>2022-04-11T07:32:00+08:00</updated>
  
    <id>http://localhost:4000/posts/Ensemble-Methods/</id>
    <content src="http://localhost:4000/posts/Ensemble-Methods/" />
    <author>
      <name>Weizhi Peng</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="Ensemble Methods" />
    
  

  
    <summary>
      





      Bagging and Boosting

Ensemble learning









Adaptive Boost











Adaboost - Adaptive Boost Training python code

import numpy as np
from prettytable import PrettyTable
class_1 = [1,2,3,4,5]
class_2 = [6,7,8,9,10]
h_error = [
    [3,4,5],
    [6,7,8],
    [1,2,9]
]


# Adaboost - Adaptive Boost Training
# -----------------------------------------------------------

item_number = len(cl...
    </summary>
  

  </entry>

  
  <entry>
    <title>Support Vector Machines</title>
    <link href="http://localhost:4000/posts/Support-Vector-Machines/" rel="alternate" type="text/html" title="Support Vector Machines" />
    <published>2022-03-31T07:32:00+08:00</published>
  
    <updated>2022-03-31T07:32:00+08:00</updated>
  
    <id>http://localhost:4000/posts/Support-Vector-Machines/</id>
    <content src="http://localhost:4000/posts/Support-Vector-Machines/" />
    <author>
      <name>Weizhi Peng</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="Support Vector Machines" />
    
  

  
    <summary>
      





      



























Nonlinear SVMs











Multi-class SVMs













SVM find hyperplane by support vectors python code

def find_weight(support_vector_l, label_l):
    # First get the final result matrix from support vector labels
    # and sum of all lambda*lable(should equal to 0)
    lambdas_result_list = []
    for i in label_l:
        lambdas_result_list.append(i)
    lamb...
    </summary>
  

  </entry>

  
  <entry>
    <title>Feature Extraction</title>
    <link href="http://localhost:4000/posts/Feature-Extraction/" rel="alternate" type="text/html" title="Feature Extraction" />
    <published>2022-03-21T07:32:00+08:00</published>
  
    <updated>2022-03-21T07:32:00+08:00</updated>
  
    <id>http://localhost:4000/posts/Feature-Extraction/</id>
    <content src="http://localhost:4000/posts/Feature-Extraction/" />
    <author>
      <name>Weizhi Peng</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="Feature Extraction" />
    
  

  
    <summary>
      





      

Principal Components Analysis













Traditional PCA python code

import numpy as np


def pca(dataset, dim):
    X = dataset
    print(X.mean(axis=1, keepdims=True))

    Y = X - X.mean(axis=1, keepdims=True)
    print("X-mean = \n",Y)
    C = []
    for i in range(len(np.transpose(Y))):
        C.append(np.dot(Y[:, [i]], np.transpose(Y[:, [i]])))
    C = np.array(C)
    C = np.sum(C, ...
    </summary>
  

  </entry>

  
  <entry>
    <title>Deep Generative Neural Networks</title>
    <link href="http://localhost:4000/posts/Deep-Generative-Neural-Networks/" rel="alternate" type="text/html" title="Deep Generative Neural Networks" />
    <published>2022-03-11T07:32:00+08:00</published>
  
    <updated>2022-03-11T07:32:00+08:00</updated>
  
    <id>http://localhost:4000/posts/Deep-Generative-Neural-Networks/</id>
    <content src="http://localhost:4000/posts/Deep-Generative-Neural-Networks/" />
    <author>
      <name>Weizhi Peng</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="Deep Generative Neural Networks" />
    
  

  
    <summary>
      





      

Maximum Likelihood



Generate image











**Generative Adversarial Networks**





















Generative Adversarial Networks python code

# calculating cost function
import numpy as np
X = [
    [1,2],
    [3,4]
]
X = np.array(X)
X_pred = [
    [5,6],
    [7,8]
]
X_pred = np.array(X_pred)

weight = np.ones(2)*0.5

# define of Discriminator
def Dx(x,a = 0.1,b = 0.2):
    x = np.tra...
    </summary>
  

  </entry>

</feed>


